from celery import shared_task
from django.conf import settings
from datetime import datetime, timedelta, timezone
import requests
import logging
import openai
from django.contrib.auth import get_user_model

from celery import shared_task
from stocks.utils import allow_request
from stocks.services import store_daily_summaries_for_user
from stocks.models import Stock, News, DailyUserNews

logger = logging.getLogger(__name__)
User = get_user_model()

@shared_task(bind=True, autoretry_for=(Exception,), retry_backoff=True, max_retries=5)
def fetch_news_for_symbol(self, symbol: str, days: int = 1):
    # --- rate-limit ì²´í¬ ---
    if not allow_request("rate_limit:finnhub", capacity=60, refill_rate=1):
        logger.warning(f"[rate-limit] {symbol} ìš”ì²­ ì°¨ë‹¨ (í† í° ì—†ìŒ)")
        raise self.retry(countdown=1)

    # --- API ìš”ì²­ ---
    today = datetime.now(timezone.utc).date()
    start_date = today - timedelta(days=days)

    url = "https://finnhub.io/api/v1/company-news"
    params = {
        "symbol": symbol,
        "from": start_date.isoformat(),
        "to": today.isoformat(),
        "token": settings.FINNHUB_API_KEY,
    }

    try:
        resp = requests.get(url, params=params, timeout=5)
        if resp.status_code == 429:
            logger.warning(f"[fetch_news_for_symbol] {symbol} â†’ 429 Too Many Requests")
            raise self.retry(countdown=2)
        resp.raise_for_status()
        articles = resp.json()
    except Exception as e:
        logger.error(f"[fetch_news_for_symbol] {symbol} ìš”ì²­ ì‹¤íŒ¨: {e}")
        raise

    logger.info(f"[fetch_news_for_symbol] {symbol} â†’ {len(articles)}ê°œ ê¸°ì‚¬ ê°€ì ¸ì˜´")
    return {"symbol": symbol, "total": len(articles)}



@shared_task
def add(x, y):
    return x + y


@shared_task(bind=True, autoretry_for=(Exception,), retry_backoff=True, max_retries=3)
def generate_news_summary_with_openai(self, user_id: int, symbol: str = None):
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ìš”ì•½ ìƒì„±
    """
    try:
        user = User.objects.get(id=user_id)
    except User.DoesNotExist:
        logger.error(f"[generate_news_summary] User {user_id} not found")
        return {"error": "User not found"}
    
    if not settings.OPENAI_API_KEY:
        logger.error("[generate_news_summary] OPENAI_API_KEY not set")
        return {"error": "OpenAI API key not configured"}
    
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
    openai.api_key = settings.OPENAI_API_KEY
    
    # ì˜¤ëŠ˜ ë‚ ì§œ
    today = datetime.now(timezone.utc).date()
    
    # ë‰´ìŠ¤ ì¡°íšŒ (ìµœê·¼ 1ì¼)
    news_query = News.objects.filter(
        stocks__symbol__iexact=symbol if symbol else None,
        published_at__date=today
    ).order_by('-published_at')[:10]  # ìµœê·¼ 10ê°œ ê¸°ì‚¬
    
    if not news_query.exists():
        logger.info(f"[generate_news_summary] No news found for {symbol or 'all stocks'} on {today}")
        return {"message": "No news found", "summaries": 0}
    
    # ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ì¤€ë¹„ (êµ¬ì¡°í™”ëœ í˜•íƒœ)
    news_texts = []
    for news in news_query:
        news_texts.append(f"ì œëª©: {news.headline}\nì¶œì²˜: {news.source}\nì‹œê°„: {news.published_at.strftime('%Y-%m-%d')}\nURL: {news.url if news.url else 'N/A'}")
    
    combined_text = "\n\n".join(news_texts)
    
    try:
        # OpenAI API í˜¸ì¶œ - ê¸ˆìœµ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        system_prompt = """ë„ˆëŠ” ê¸ˆìœµ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ AIë‹¤. ì•„ë˜ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ íˆ¬ììê°€ ë¹ ë¥´ê²Œ ì½ì„ ìˆ˜ ìˆëŠ”
'í•˜ë£¨ì¹˜ ì¢…ëª© ë¦¬í¬íŠ¸'ë¥¼ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë¼. ê³¼ì¥/ê¶Œìœ /íˆ¬ììë¬¸ í‘œí˜„ì€ ê¸ˆì§€í•œë‹¤.

[ê·œì¹™]
1) ë°˜ë“œì‹œ ì•„ë˜ 'ì¶œë ¥ í˜•ì‹' ì„¹ì…˜ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•œë‹¤(ì„¹ì…˜ ì œëª©/ì´ëª¨ì§€ ê³ ì •).
2) ê°™ì€ ì´ë²¤íŠ¸ë¥¼ ë‹¤ë£¬ ì¤‘ë³µ/í›„ì† ê¸°ì‚¬ëŠ” í•©ì³ì„œ í•œ ì¤„ë¡œ í†µí•© ìš”ì•½í•œë‹¤.
3) ì‚¬ì‹¤ë§Œ ê¸°ìˆ í•˜ê³ , ìˆ˜ì¹˜/ë‚ ì§œ/ì¸ìš©ì€ ê¸°ì‚¬ì— ìˆëŠ” ê²ƒë§Œ ì‚¬ìš©í•œë‹¤.
   - ìˆ«ì/í¼ì„¼íŠ¸/ë‚ ì§œë¥¼ ì„ì˜ë¡œ ì¶”ì •/ì°½ì‘í•˜ì§€ ë§ê³ , ì—†ìœ¼ë©´ ì“°ì§€ ë§ì•„ë¼.
4) ë£¨ë¨¸Â·ë¯¸í™•ì • ë³´ë„ëŠ” ëª…ì‹œì ìœ¼ë¡œ "ë£¨ë¨¸/ë¯¸í™•ì •"ìœ¼ë¡œ í‘œì‹œí•˜ê³  ê³¼ë„í•œ ì¶”ë¡  ê¸ˆì§€.
5) ê°€ê²©/ìˆ˜ê¸‰Â·ì¼ì • ì…ë ¥ì´ ì—†ìœ¼ë©´ "ë°ì´í„° ë¯¸ì œê³µ" ë˜ëŠ” "ì—†ìŒ"ìœ¼ë¡œ í‘œê¸°í•œë‹¤.
6) 'ì „ì²´ ë¶„ìœ„ê¸°'ëŠ” ê¸ì •/ì¤‘ë¦½/ë¶€ì •/í˜¼í•© ì¤‘ í•˜ë‚˜ë¡œ ì„ íƒí•˜ê³ , í•œ ë¬¸ì¥ ê·¼ê±°ì™€
   0~100ì˜ confidenceë¥¼ í•¨ê»˜ ì œì‹œí•œë‹¤(ì¶œì²˜ ìˆ˜/ì¼ì¹˜ë„/ëª…í™•ì„± ê¸°ë°˜).
7) ë§ˆì§€ë§‰ì— 'JSON(ë¨¸ì‹ ë¦¬ë”ë¸”)' ë¸”ë¡ì„ ë°˜ë“œì‹œ ì²¨ë¶€í•œë‹¤(í‚¤/ìŠ¤í‚¤ë§ˆ ê³ ì •).
8) í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•œë‹¤. ê´‘ê³ ì„±Â·ì¡ë‹´Â·íˆ¬ìì¡°ì–¸ ë¬¸êµ¬ëŠ” ê¸ˆì§€í•œë‹¤.

[ì¶œë ¥ í˜•ì‹]
ğŸ“Š {DATE} {TICKER} ({COMPANY}) ë‰´ìŠ¤ ìš”ì•½

âœ… 1. í•µì‹¬ ìš”ì•½:
- (3~5ì¤„) ì˜¤ëŠ˜ ê¸°ì‚¬ë“¤ì˜ ê³µí†µ í•µì‹¬ì„ ì‚¬ì‹¤ ìœ„ì£¼ë¡œ í†µí•© ì •ë¦¬.
- ì¤‘ë³µ ì´ìŠˆëŠ” ë¬¶ê³ , ìƒˆë¡œìš´ ì „ê°œê°€ ìˆìœ¼ë©´ "ì—…ë°ì´íŠ¸"ë¡œ í‘œê¸°.

ğŸ’¡ 2. íˆ¬ì ê´€ì  ì£¼ìš” í¬ì¸íŠ¸:
- ê¸ì •: (2~4ê°œ) ê¸°ìˆ /ì‹¤ì /ìˆ˜ìš”/ê²½ìŸë ¥/íŒŒíŠ¸ë„ˆì‹­ ë“±
- ì£¼ì˜Â·ë¦¬ìŠ¤í¬: (2~4ê°œ) ì†Œì†¡/ê·œì œ/ê³µê¸‰ë§/ìˆ˜ìš”ë‘”í™”/ì§€ì—° ë“±

ğŸ“ˆ 3. ê°€ê²©/ìˆ˜ê¸‰ ìŠ¤ëƒ…ìƒ·:
- í˜„ì¬ê°€/ë“±ë½ë¥ /ì‹œê°€/ì „ì¼ì¢…ê°€ ìš”ì•½: ë°ì´í„° ë¯¸ì œê³µ
- íŠ¹ì´ì‚¬í•­(ê±°ë˜ëŸ‰/í”„ë¦¬Â·ì• í”„í„°ë§ˆì¼“ ë“±): ìˆìœ¼ë©´ 1ì¤„, ì—†ìœ¼ë©´ ìƒëµ

ğŸ—“ï¸ 4. ë‹¤ê°€ì˜¤ëŠ” ì¼ì •/ì´‰ë§¤:
- ë¦¬ìŠ¤íŠ¸ í˜•ì‹(ì˜ˆ: 07-10 ì œí’ˆ ì´ë²¤íŠ¸, 07-25 ì‹¤ì ë°œí‘œ). ì—†ìœ¼ë©´ "ì—†ìŒ"

ğŸŒ 5. ì„¹í„°/ê±°ì‹œ í•œ ì¤„ ìš”ì•½:
- ë°ì´í„° ë¯¸ì œê³µ

ğŸ¯ 6. ì „ì²´ ë¶„ìœ„ê¸°:
- í‰ê°€: [ê¸ì •/ì¤‘ë¦½/ë¶€ì •/í˜¼í•©], ê·¼ê±° í•œ ë¬¸ì¥.
- confidence: NN/100

ğŸ“ 7. 200ì ë‚´ ìš”ì•½:
- (ê³µë°± í¬í•¨ 200ì ì´ë‚´ë¡œ í•µì‹¬ ë©”ì‹œì§€ í•œ ë‹¨ë½)

ğŸ”— 8. ì¶œì²˜(ìµœëŒ€ 5ê°œ, ì¤‘ë³µ ì œê±°):
- ë§¤ì²´ | YYYY-MM-DD | ì£¼ìš” í‚¤ì›Œë“œ(ìµœëŒ€ 5ë‹¨ì–´) - (ë£¨ë¨¸/ë¯¸í™•ì • ì‹œ í‘œì‹œ)
- ê° í•­ëª© ëì— URL 1ê°œ í¬í•¨

---

JSON(ë¨¸ì‹ ë¦¬ë”ë¸”)  â€» ë°˜ë“œì‹œ ì•„ë˜ ìŠ¤í‚¤ë§ˆ, í‚¤ ìˆœì„œ/ì˜ë¬¸í‚¤ ìœ ì§€
{
  "date": "{DATE}",
  "ticker": "{TICKER}",
  "company": "{COMPANY}",
  "sentiment": "positive|neutral|negative|mixed",
  "confidence": 0-100,
  "highlights": ["...", "..."],             // í•µì‹¬ ìš”ì•½ í¬ì¸íŠ¸ 2~5ê°œ
  "bull_points": ["...", "..."],            // ê¸ì • ìš”ì¸
  "bear_points": ["...", "..."],            // ë¦¬ìŠ¤í¬ ìš”ì¸
  "price_snapshot": {
    "prev_close": number|null,
    "open": number|null,
    "current": number|null,
    "change_pct": number|null,
    "premarket": number|null,
    "after_hours": number|null,
    "volume_note": string|null
  },
  "upcoming": [ { "type":"earnings|product_event|regulatory|other", "date":"YYYY-MM-DD" } ],
  "sector_note": string|null,
  "summary_200": "ê³µë°± í¬í•¨ 200ì ì´ë‚´",
  "sources": [
    { "source":"Reuters", "url":"https://...", "published_at":"YYYY-MM-DD", "topic":"í‚¤ì›Œë“œ", "status":"confirmed|rumor" }
  ],
  "novelty": "new|ongoing|update|rumor",    // ì˜¤ëŠ˜ ë³´ë„ì˜ ì‹ ì„ ë„/ìƒíƒœ
  "risk_flags": ["lawsuit","regulation","supply_chain","delay"]  // í•´ë‹¹ ì‹œì—ë§Œ
}"""

        user_prompt = f"""ğŸ“Š {today} {symbol} ë‰´ìŠ¤ ìš”ì•½

[ì…ë ¥]
- ë‚ ì§œ: {today}
- í‹°ì»¤/íšŒì‚¬: {symbol}
- ê¸°ì‚¬ ëª©ë¡:
{combined_text}

ìœ„ ë‰´ìŠ¤ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ê¸ˆìœµ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system", 
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": user_prompt
                }
            ],
            max_tokens=1500,  # ë” ê¸´ ì‘ë‹µì„ ìœ„í•´ í† í° ìˆ˜ ì¦ê°€
            temperature=0.3   # ë” ì¼ê´€ëœ ë¶„ì„ì„ ìœ„í•´ ë‚®ì¶¤
        )
        
        summary = response.choices[0].message.content
        
        # ìš”ì•½ ì €ì¥
        if symbol:
            # íŠ¹ì • ì¢…ëª© ìš”ì•½
            try:
                stock = Stock.objects.get(symbol__iexact=symbol)
                DailyUserNews.objects.update_or_create(
                    user=user,
                    date=today,
                    stock=stock,
                    defaults={"summary": summary}
                )
                logger.info(f"[generate_news_summary] Summary saved for {user.email} - {symbol}")
                return {"message": "Summary generated successfully", "symbol": symbol, "summary": summary}
            except Stock.DoesNotExist:
                logger.error(f"[generate_news_summary] Stock {symbol} not found")
                return {"error": f"Stock {symbol} not found"}
        else:
            # ì‚¬ìš©ìì˜ ëª¨ë“  ê´€ì‹¬ì¢…ëª©ì— ëŒ€í•œ ìš”ì•½
            favorite_stocks = user.favorites.values_list('stock__symbol', flat=True)
            summaries_by_symbol = {}
            
            for stock_symbol in favorite_stocks:
                try:
                    stock = Stock.objects.get(symbol__iexact=stock_symbol)
                    # ê° ì¢…ëª©ë³„ë¡œ ê°œë³„ ìš”ì•½ ìƒì„± (ê°„ë‹¨í•œ ë²„ì „)
                    stock_news = news_query.filter(stocks__symbol__iexact=stock_symbol)
                    if stock_news.exists():
                        stock_texts = []
                        for news in stock_news[:5]:  # ê° ì¢…ëª©ë‹¹ ìµœëŒ€ 5ê°œ ê¸°ì‚¬
                            stock_texts.append(f"ì œëª©: {news.headline}\nì¶œì²˜: {news.source}\nì‹œê°„: {news.published_at.strftime('%Y-%m-%d')}\nURL: {news.url if news.url else 'N/A'}")
                        stock_combined = "\n\n".join(stock_texts)
                        
                        stock_response = openai.chat.completions.create(
                            model="gpt-3.5-turbo",
                            messages=[
                                {
                                    "role": "system", 
                                    "content": system_prompt
                                },
                                {
                                    "role": "user",
                                    "content": f"""ğŸ“Š {today} {stock_symbol} ë‰´ìŠ¤ ìš”ì•½

[ì…ë ¥]
- ë‚ ì§œ: {today}
- í‹°ì»¤/íšŒì‚¬: {stock_symbol}
- ê¸°ì‚¬ ëª©ë¡:
{stock_combined}

ìœ„ ë‰´ìŠ¤ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ê¸ˆìœµ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."""
                                }
                            ],
                            max_tokens=1500,
                            temperature=0.3
                        )
                        
                        summaries_by_symbol[stock_symbol] = stock_response.choices[0].message.content
                except Exception as e:
                    logger.error(f"[generate_news_summary] Error processing {stock_symbol}: {e}")
                    continue
            
            # ìš”ì•½ ì €ì¥
            saved_count = store_daily_summaries_for_user(user, summaries_by_symbol)
            logger.info(f"[generate_news_summary] {saved_count} summaries saved for {user.email}")
            return {"message": "Summaries generated successfully", "saved_count": saved_count, "summaries": summaries_by_symbol}
            
    except Exception as e:
        logger.error(f"[generate_news_summary] OpenAI API error: {e}")
        raise self.retry(countdown=60)  # 1ë¶„ í›„ ì¬ì‹œë„


@shared_task
def daily_news_summary_batch():
    """
    ë§¤ì¼ ì‹¤í–‰ë˜ëŠ” ë°°ì¹˜ ì‘ì—…: ëª¨ë“  í™œì„± ì‚¬ìš©ìì˜ ê´€ì‹¬ì¢…ëª© ë‰´ìŠ¤ ìš”ì•½ ìƒì„±
    """
    logger.info("[daily_news_summary_batch] Starting daily summary batch")
    
    # í™œì„± ì‚¬ìš©ìë“¤ì˜ ê´€ì‹¬ì¢…ëª© ìˆ˜ì§‘
    users_with_favorites = User.objects.filter(
        favorites__isnull=False
    ).distinct()
    
    total_tasks = 0
    for user in users_with_favorites:
        # ê° ì‚¬ìš©ìë³„ë¡œ ìš”ì•½ ìƒì„± íƒœìŠ¤í¬ íì— ì¶”ê°€
        generate_news_summary_with_openai.delay(user.id)
        total_tasks += 1
    
    logger.info(f"[daily_news_summary_batch] Queued {total_tasks} summary tasks")
    return {"message": f"Queued {total_tasks} summary tasks"}